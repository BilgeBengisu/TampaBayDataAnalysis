{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc626fad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'FINALIZED_Unlabeled_Data_ALL_Available_Descriptions_EMOJIS_UNCHANGED.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m academia \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39macad\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m tourBiz \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtourbiz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(filepath)\n\u001b[1;32m     35\u001b[0m \u001b[39m# df = df[((df[hand_label] == 'media') | (df[hand_label] == tourBiz) |(df[hand_label] == academia) | (df[hand_label] == government) | (\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m#        df[hand_label] == 'other'))]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]]  \u001b[39m# keep only relevant columns\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FINALIZED_Unlabeled_Data_ALL_Available_Descriptions_EMOJIS_UNCHANGED.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "tag_map['AS'] = wn.ADJ_SAT\n",
    "\n",
    "# filepath = \"finalized_8K_accounts.csv\"\n",
    "# filepath = \"UNLABELED_accounts_emojis_replaced.csv\"\n",
    "filepath = \"FINALIZED_Unlabeled_Data_ALL_Available_Descriptions_EMOJIS_UNCHANGED.csv\"\n",
    "hand_label = \"hand.label\"\n",
    "government = \"gov\"\n",
    "academia = \"acad\"\n",
    "tourBiz = \"tourbiz\"\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# df = df[((df[hand_label] == 'media') | (df[hand_label] == tourBiz) |(df[hand_label] == academia) | (df[hand_label] == government) | (\n",
    "#        df[hand_label] == 'other'))]\n",
    "\n",
    "df = df[['username', 'description']]  # keep only relevant columns\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_not_changed = ['media']\n",
    "\n",
    "\n",
    "def preprocessing(row):\n",
    "    if str(row) == \"nan\":\n",
    "        lemma = \"\"\n",
    "    else:\n",
    "        row = str(row).lower()\n",
    "        row = word_tokenize(row)  # tokenize\n",
    "        lemma = [lemmatizer.lemmatize(token, tag_map[tag[0]]) if token not in words_not_changed else token for\n",
    "                 token, tag in pos_tag(row)]  # lemmatization, depending on part-of-speech\n",
    "        lemma = [\"\" if re.search(r'\\b[0-9]+\\b\\s*', lem) else lem for lem in lemma]  # removing\n",
    "    return str(lemma)\n",
    "\n",
    "\n",
    "df['description_lemmatized'] = df['description'].apply(preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b4d3f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14599, 3)\n",
      "(13242, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove all the empty descriptions\n",
    "print(df.shape)\n",
    "print(df[df['description_lemmatized'] != \"\"].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57a23e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13242, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove all the empty descriptions\n",
    "df = df[df['description_lemmatized'] != \"\"]\n",
    "print(df.shape)\n",
    "#df[hand_label]\n",
    "#print(df.shape)\n",
    "#df[df['description_lemmatized'] != \"\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7612c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-indexing the remaining observations\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2af8cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# print(type(df[['description_lemmatized']]))\n",
    "embeddings = model.encode(df['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a13dfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'SVM_BOW_unweighted_enhanced_model.pickle'\n",
    "filename = 'SVM_BERT_unweighted_enhanced_model_full(1, 2).pickle'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "X_test = embeddings\n",
    "\n",
    "bag_of_words_y_pred_test = loaded_model.predict(X_test)\n",
    "\n",
    "bag_of_words_y_pred_test\n",
    "\n",
    "pred_prob = loaded_model.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc1d7478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>0.009342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>other</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>other</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>other</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         0         1         2         3         4\n",
       "0      other  0.000585  0.001464  0.001155  0.992605  0.004191\n",
       "1      other  0.004342  0.000639  0.003219  0.982458  0.009342\n",
       "2      other  0.005846  0.015085  0.049567  0.928598  0.000904\n",
       "3      other  0.001891  0.001057  0.002662  0.994019  0.000370\n",
       "4      other  0.006474  0.001169  0.005799  0.983785  0.002772\n",
       "...      ...       ...       ...       ...       ...       ...\n",
       "13237  other  0.001823  0.010809  0.064314  0.785241  0.137813\n",
       "13238  other  0.007914  0.001513  0.048221  0.941749  0.000602\n",
       "13239  other  0.492738  0.001781  0.002790  0.502624  0.000067\n",
       "13240  other  0.012996  0.000962  0.000605  0.984303  0.001134\n",
       "13241  other  0.001773  0.010881  0.021937  0.965021  0.000388\n",
       "\n",
       "[13242 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob\n",
    "bag_of_words_y_pred_test\n",
    "pd.concat([pd.DataFrame(bag_of_words_y_pred_test), pd.DataFrame(pred_prob)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ae85ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13242, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbd3b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13242, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_df = pd.DataFrame(pred_prob, columns = ['acad_prob','gov_prob','media_prob','other_prob', 'tourbiz_prob'])\n",
    "\n",
    "bag_of_words_y_pred_test.size\n",
    "\n",
    "df['hand.label_simplified'] = bag_of_words_y_pred_test\n",
    "#df = df.drop(columns=['description_lemmatized'])\n",
    "df1 = pd.concat([df, pred_prob_df], axis=1)\n",
    "#df1 = pd.DataFrame(my_array, columns = ['acad_prob','gov_prob','media_prob','other_prob', 'tourbiz_prob'])\n",
    "\n",
    "df1\n",
    "df1.shape\n",
    "#pred_prob_df.shape\n",
    "#len(bag_of_words_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0141ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lemmatized</th>\n",
       "      <th>hand.label_simplified</th>\n",
       "      <th>acad_prob</th>\n",
       "      <th>gov_prob</th>\n",
       "      <th>media_prob</th>\n",
       "      <th>other_prob</th>\n",
       "      <th>tourbiz_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeChatNoire4</td>\n",
       "      <td>#VOTE BLUE 2022 🌊🇺🇸🌊 #BuyARepublicanToday! no ...</td>\n",
       "      <td>['#', 'vote', 'blue', '', '🌊🇺🇸🌊', '#', 'buyare...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SethPlatt</td>\n",
       "      <td>Creator Collector Cultivator Art Web3 ENS AI S...</td>\n",
       "      <td>['creator', 'collector', 'cultivator', 'art', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>0.009342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eco_voice</td>\n",
       "      <td>A non-partisan, independent, volunteer run org...</td>\n",
       "      <td>['a', 'non-partisan', ',', 'independent', ',',...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corn4Harvick</td>\n",
       "      <td>*Flo-Grown* 🇺🇸 🇺🇸 Jesus sent me back to straig...</td>\n",
       "      <td>['*', 'flo-grown', '*', '🇺🇸', '🇺🇸', 'jesus', '...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>memorabiliaddy</td>\n",
       "      <td>Healthcare Professional * Dad to Two * MSU Alu...</td>\n",
       "      <td>['healthcare', 'professional', '*', 'dad', 'to...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>EvergreenZephyr</td>\n",
       "      <td>Wichita, Kansas, United (sic) States. Parody a...</td>\n",
       "      <td>['wichita', ',', 'kansa', ',', 'united', '(', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>johntfox</td>\n",
       "      <td>Madeleine &amp; Marin's Dad | Gin Enthusiast | Twe...</td>\n",
       "      <td>['madeleine', '&amp;', 'marin', \"'s\", 'dad', '|', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>SeGreene</td>\n",
       "      <td>Cranky former nurse and current plant patholog...</td>\n",
       "      <td>['cranky', 'former', 'nurse', 'and', 'current'...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>CherylLasse</td>\n",
       "      <td>Passionate about the environment, science and ...</td>\n",
       "      <td>['passionate', 'about', 'the', 'environment', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>jen_pic</td>\n",
       "      <td>🚫socialism. Pay your debts, ALL OF THEM! Nothi...</td>\n",
       "      <td>['🚫socialism', '.', 'pay', 'your', 'debt', ','...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13242 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username                                        description  \\\n",
       "0         LeChatNoire4  #VOTE BLUE 2022 🌊🇺🇸🌊 #BuyARepublicanToday! no ...   \n",
       "1            SethPlatt  Creator Collector Cultivator Art Web3 ENS AI S...   \n",
       "2            eco_voice  A non-partisan, independent, volunteer run org...   \n",
       "3         Corn4Harvick  *Flo-Grown* 🇺🇸 🇺🇸 Jesus sent me back to straig...   \n",
       "4       memorabiliaddy  Healthcare Professional * Dad to Two * MSU Alu...   \n",
       "...                ...                                                ...   \n",
       "13237  EvergreenZephyr  Wichita, Kansas, United (sic) States. Parody a...   \n",
       "13238         johntfox  Madeleine & Marin's Dad | Gin Enthusiast | Twe...   \n",
       "13239         SeGreene  Cranky former nurse and current plant patholog...   \n",
       "13240      CherylLasse  Passionate about the environment, science and ...   \n",
       "13241          jen_pic  🚫socialism. Pay your debts, ALL OF THEM! Nothi...   \n",
       "\n",
       "                                  description_lemmatized  \\\n",
       "0      ['#', 'vote', 'blue', '', '🌊🇺🇸🌊', '#', 'buyare...   \n",
       "1      ['creator', 'collector', 'cultivator', 'art', ...   \n",
       "2      ['a', 'non-partisan', ',', 'independent', ',',...   \n",
       "3      ['*', 'flo-grown', '*', '🇺🇸', '🇺🇸', 'jesus', '...   \n",
       "4      ['healthcare', 'professional', '*', 'dad', 'to...   \n",
       "...                                                  ...   \n",
       "13237  ['wichita', ',', 'kansa', ',', 'united', '(', ...   \n",
       "13238  ['madeleine', '&', 'marin', \"'s\", 'dad', '|', ...   \n",
       "13239  ['cranky', 'former', 'nurse', 'and', 'current'...   \n",
       "13240  ['passionate', 'about', 'the', 'environment', ...   \n",
       "13241  ['🚫socialism', '.', 'pay', 'your', 'debt', ','...   \n",
       "\n",
       "      hand.label_simplified  acad_prob  gov_prob  media_prob  other_prob  \\\n",
       "0                     other   0.000585  0.001464    0.001155    0.992605   \n",
       "1                     other   0.004342  0.000639    0.003219    0.982458   \n",
       "2                     other   0.005846  0.015085    0.049567    0.928598   \n",
       "3                     other   0.001891  0.001057    0.002662    0.994019   \n",
       "4                     other   0.006474  0.001169    0.005799    0.983785   \n",
       "...                     ...        ...       ...         ...         ...   \n",
       "13237                 other   0.001823  0.010809    0.064314    0.785241   \n",
       "13238                 other   0.007914  0.001513    0.048221    0.941749   \n",
       "13239                 other   0.492738  0.001781    0.002790    0.502624   \n",
       "13240                 other   0.012996  0.000962    0.000605    0.984303   \n",
       "13241                 other   0.001773  0.010881    0.021937    0.965021   \n",
       "\n",
       "       tourbiz_prob  \n",
       "0          0.004191  \n",
       "1          0.009342  \n",
       "2          0.000904  \n",
       "3          0.000370  \n",
       "4          0.002772  \n",
       "...             ...  \n",
       "13237      0.137813  \n",
       "13238      0.000602  \n",
       "13239      0.000067  \n",
       "13240      0.001134  \n",
       "13241      0.000388  \n",
       "\n",
       "[13242 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f0ec6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'SVM_BERT_unweighted_UNLABELED_PREDICTED_accounts_W_PROBABILITIES_emojis_unchanged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce37dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea2422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e37f6f24e9a9f73ff6720cc463cd31ad7ef16f22c85d3da331e44c0f6e80d360"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
