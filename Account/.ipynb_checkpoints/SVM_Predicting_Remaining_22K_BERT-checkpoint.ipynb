{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc626fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             username                                        description  \\\n",
      "0       ChungSunPark4                                      attempt me!!!   \n",
      "1        LucilaQuanti  Me gusta la gente con sentido del humor, alegr...   \n",
      "2       patdefranchis  I love people with a large dose of humor & a r...   \n",
      "3       saravastiares  Have courage & Be Kind. Where there is kindnes...   \n",
      "4      TheShogunGamer  Video Game Extraordinaire üéÆ Polyamorous ‚ù§ Disa...   \n",
      "...               ...                                                ...   \n",
      "3493   ChrisFischer07                                                NaN   \n",
      "3494       ryantpa813  Eight One Three Sports\\nBolts, Bucs, Rays, Soo...   \n",
      "3495  TueNiteRockStar                                                NaN   \n",
      "3496     purpletang99  i tweet my opinions only. yes there are except...   \n",
      "3497       firefly909  Unapologetic bleeding heart liberal. Hate liar...   \n",
      "\n",
      "                                 description_lemmatized  \n",
      "0                      ['attempt', 'me', '!', '!', '!']  \n",
      "1     ['me', 'gusta', 'la', 'gente', 'con', 'sentido...  \n",
      "2     ['i', 'love', 'people', 'with', 'a', 'large', ...  \n",
      "3     ['have', 'courage', '&', 'be', 'kind', '.', 'w...  \n",
      "4     ['video', 'game', 'extraordinaire', 'üéÆ', 'poly...  \n",
      "...                                                 ...  \n",
      "3493                                                     \n",
      "3494  ['eight', 'one', 'three', 'sport', 'bolt', ','...  \n",
      "3495                                                     \n",
      "3496  ['i', 'tweet', 'my', 'opinion', 'only', '.', '...  \n",
      "3497  ['unapologetic', 'bleed', 'heart', 'liberal', ...  \n",
      "\n",
      "[3498 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "tag_map['AS'] = wn.ADJ_SAT\n",
    "\n",
    "# filepath = \"finalized_8K_accounts.csv\"\n",
    "# filepath = \"UNLABELED_accounts_emojis_replaced.csv\"\n",
    "filepath = \"Spill_Accounts_To_Be_Labeled.csv\"\n",
    "hand_label = \"hand.label\"\n",
    "government = \"gov\"\n",
    "academia = \"acad\"\n",
    "tourBiz = \"tourbiz\"\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# df = df[((df[hand_label] == 'media') | (df[hand_label] == tourBiz) |(df[hand_label] == academia) | (df[hand_label] == government) | (\n",
    "#        df[hand_label] == 'other'))]\n",
    "\n",
    "df = df[['username', 'description']]  # keep only relevant columns\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_not_changed = ['media']\n",
    "\n",
    "\n",
    "def preprocessing(row):\n",
    "    if str(row) == \"nan\":\n",
    "        lemma = \"\"\n",
    "    else:\n",
    "        row = str(row).lower()\n",
    "        row = word_tokenize(row)  # tokenize\n",
    "        lemma = [lemmatizer.lemmatize(token, tag_map[tag[0]]) if token not in words_not_changed else token for\n",
    "                 token, tag in pos_tag(row)]  # lemmatization, depending on part-of-speech\n",
    "        lemma = [\"\" if re.search(r'\\b[0-9]+\\b\\s*', lem) else lem for lem in lemma]  # removing\n",
    "    return str(lemma)\n",
    "\n",
    "\n",
    "df['description_lemmatized'] = df['description'].apply(preprocessing)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b4d3f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 3)\n",
      "(2908, 3)\n"
     ]
    }
   ],
   "source": [
    "# all the empty descriptions\n",
    "print(df.shape)\n",
    "print(df[df['description_lemmatized'] != \"\"].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57a23e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590, 3)\n",
      "(2908, 3)\n"
     ]
    }
   ],
   "source": [
    "# Remove all the empty descriptions\n",
    "empty_rows = df[df['description_lemmatized'] == \"\"]\n",
    "print(empty_rows.shape)\n",
    "df = df[df['description_lemmatized'] != \"\"]\n",
    "print(df.shape)\n",
    "#df[hand_label]\n",
    "#print(df.shape)\n",
    "#df[df['description_lemmatized'] != \"\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7612c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-indexing the remaining observations\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af8cfdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tensor' from 'torch' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(type(df[['description_lemmatized']]))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, nn\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tensor' from 'torch' (unknown location)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# print(type(df[['description_lemmatized']]))\n",
    "embeddings = model.encode(df['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a13dfb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'SVM_BOW_unweighted_enhanced_model.pickle'\n",
    "filename = 'SVM_BERT_unweighted_enhanced_model_full(1, 2).pickle'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "X_test = embeddings\n",
    "\n",
    "bag_of_words_y_pred_test = loaded_model.predict(X_test)\n",
    "\n",
    "bag_of_words_y_pred_test\n",
    "\n",
    "pred_prob = loaded_model.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc1d7478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>0.009342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>other</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>other</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>other</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>other</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13242 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         0         1         2         3         4\n",
       "0      other  0.000585  0.001464  0.001155  0.992605  0.004191\n",
       "1      other  0.004342  0.000639  0.003219  0.982458  0.009342\n",
       "2      other  0.005846  0.015085  0.049567  0.928598  0.000904\n",
       "3      other  0.001891  0.001057  0.002662  0.994019  0.000370\n",
       "4      other  0.006474  0.001169  0.005799  0.983785  0.002772\n",
       "...      ...       ...       ...       ...       ...       ...\n",
       "13237  other  0.001823  0.010809  0.064314  0.785241  0.137813\n",
       "13238  other  0.007914  0.001513  0.048221  0.941749  0.000602\n",
       "13239  other  0.492738  0.001781  0.002790  0.502624  0.000067\n",
       "13240  other  0.012996  0.000962  0.000605  0.984303  0.001134\n",
       "13241  other  0.001773  0.010881  0.021937  0.965021  0.000388\n",
       "\n",
       "[13242 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob\n",
    "bag_of_words_y_pred_test\n",
    "pd.concat([pd.DataFrame(bag_of_words_y_pred_test), pd.DataFrame(pred_prob)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ae85ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13242, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbd3b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13242, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_df = pd.DataFrame(pred_prob, columns = ['acad_prob','gov_prob','media_prob','other_prob', 'tourbiz_prob'])\n",
    "\n",
    "bag_of_words_y_pred_test.size\n",
    "\n",
    "df['hand.label_simplified'] = bag_of_words_y_pred_test\n",
    "#df = df.drop(columns=['description_lemmatized'])\n",
    "df1 = pd.concat([df, pred_prob_df], axis=1)\n",
    "#df1 = pd.DataFrame(my_array, columns = ['acad_prob','gov_prob','media_prob','other_prob', 'tourbiz_prob'])\n",
    "\n",
    "df1\n",
    "df1.shape\n",
    "#pred_prob_df.shape\n",
    "#len(bag_of_words_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0141ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>description_lemmatized</th>\n",
       "      <th>hand.label_simplified</th>\n",
       "      <th>acad_prob</th>\n",
       "      <th>gov_prob</th>\n",
       "      <th>media_prob</th>\n",
       "      <th>other_prob</th>\n",
       "      <th>tourbiz_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeChatNoire4</td>\n",
       "      <td>#VOTE BLUE 2022 üåäüá∫üá∏üåä #BuyARepublicanToday! no ...</td>\n",
       "      <td>['#', 'vote', 'blue', '', 'üåäüá∫üá∏üåä', '#', 'buyare...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.992605</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SethPlatt</td>\n",
       "      <td>Creator Collector Cultivator Art Web3 ENS AI S...</td>\n",
       "      <td>['creator', 'collector', 'cultivator', 'art', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.982458</td>\n",
       "      <td>0.009342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eco_voice</td>\n",
       "      <td>A non-partisan, independent, volunteer run org...</td>\n",
       "      <td>['a', 'non-partisan', ',', 'independent', ',',...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corn4Harvick</td>\n",
       "      <td>*Flo-Grown* üá∫üá∏ üá∫üá∏ Jesus sent me back to straig...</td>\n",
       "      <td>['*', 'flo-grown', '*', 'üá∫üá∏', 'üá∫üá∏', 'jesus', '...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>memorabiliaddy</td>\n",
       "      <td>Healthcare Professional * Dad to Two * MSU Alu...</td>\n",
       "      <td>['healthcare', 'professional', '*', 'dad', 'to...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>EvergreenZephyr</td>\n",
       "      <td>Wichita, Kansas, United (sic) States. Parody a...</td>\n",
       "      <td>['wichita', ',', 'kansa', ',', 'united', '(', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.064314</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>johntfox</td>\n",
       "      <td>Madeleine &amp; Marin's Dad | Gin Enthusiast | Twe...</td>\n",
       "      <td>['madeleine', '&amp;', 'marin', \"'s\", 'dad', '|', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>SeGreene</td>\n",
       "      <td>Cranky former nurse and current plant patholog...</td>\n",
       "      <td>['cranky', 'former', 'nurse', 'and', 'current'...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>CherylLasse</td>\n",
       "      <td>Passionate about the environment, science and ...</td>\n",
       "      <td>['passionate', 'about', 'the', 'environment', ...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>jen_pic</td>\n",
       "      <td>üö´socialism. Pay your debts, ALL OF THEM! Nothi...</td>\n",
       "      <td>['üö´socialism', '.', 'pay', 'your', 'debt', ','...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13242 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username                                        description  \\\n",
       "0         LeChatNoire4  #VOTE BLUE 2022 üåäüá∫üá∏üåä #BuyARepublicanToday! no ...   \n",
       "1            SethPlatt  Creator Collector Cultivator Art Web3 ENS AI S...   \n",
       "2            eco_voice  A non-partisan, independent, volunteer run org...   \n",
       "3         Corn4Harvick  *Flo-Grown* üá∫üá∏ üá∫üá∏ Jesus sent me back to straig...   \n",
       "4       memorabiliaddy  Healthcare Professional * Dad to Two * MSU Alu...   \n",
       "...                ...                                                ...   \n",
       "13237  EvergreenZephyr  Wichita, Kansas, United (sic) States. Parody a...   \n",
       "13238         johntfox  Madeleine & Marin's Dad | Gin Enthusiast | Twe...   \n",
       "13239         SeGreene  Cranky former nurse and current plant patholog...   \n",
       "13240      CherylLasse  Passionate about the environment, science and ...   \n",
       "13241          jen_pic  üö´socialism. Pay your debts, ALL OF THEM! Nothi...   \n",
       "\n",
       "                                  description_lemmatized  \\\n",
       "0      ['#', 'vote', 'blue', '', 'üåäüá∫üá∏üåä', '#', 'buyare...   \n",
       "1      ['creator', 'collector', 'cultivator', 'art', ...   \n",
       "2      ['a', 'non-partisan', ',', 'independent', ',',...   \n",
       "3      ['*', 'flo-grown', '*', 'üá∫üá∏', 'üá∫üá∏', 'jesus', '...   \n",
       "4      ['healthcare', 'professional', '*', 'dad', 'to...   \n",
       "...                                                  ...   \n",
       "13237  ['wichita', ',', 'kansa', ',', 'united', '(', ...   \n",
       "13238  ['madeleine', '&', 'marin', \"'s\", 'dad', '|', ...   \n",
       "13239  ['cranky', 'former', 'nurse', 'and', 'current'...   \n",
       "13240  ['passionate', 'about', 'the', 'environment', ...   \n",
       "13241  ['üö´socialism', '.', 'pay', 'your', 'debt', ','...   \n",
       "\n",
       "      hand.label_simplified  acad_prob  gov_prob  media_prob  other_prob  \\\n",
       "0                     other   0.000585  0.001464    0.001155    0.992605   \n",
       "1                     other   0.004342  0.000639    0.003219    0.982458   \n",
       "2                     other   0.005846  0.015085    0.049567    0.928598   \n",
       "3                     other   0.001891  0.001057    0.002662    0.994019   \n",
       "4                     other   0.006474  0.001169    0.005799    0.983785   \n",
       "...                     ...        ...       ...         ...         ...   \n",
       "13237                 other   0.001823  0.010809    0.064314    0.785241   \n",
       "13238                 other   0.007914  0.001513    0.048221    0.941749   \n",
       "13239                 other   0.492738  0.001781    0.002790    0.502624   \n",
       "13240                 other   0.012996  0.000962    0.000605    0.984303   \n",
       "13241                 other   0.001773  0.010881    0.021937    0.965021   \n",
       "\n",
       "       tourbiz_prob  \n",
       "0          0.004191  \n",
       "1          0.009342  \n",
       "2          0.000904  \n",
       "3          0.000370  \n",
       "4          0.002772  \n",
       "...             ...  \n",
       "13237      0.137813  \n",
       "13238      0.000602  \n",
       "13239      0.000067  \n",
       "13240      0.001134  \n",
       "13241      0.000388  \n",
       "\n",
       "[13242 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f0ec6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'SVM_BERT_unweighted_UNLABELED_PREDICTED_accounts_W_PROBABILITIES_emojis_unchanged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1ce37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spill_labeled_accs = pd.read_csv(\"Spill_Labeled.csv\")\n",
    "#spill_labeled_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4ea2422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26172\n",
      "hand.label_simplified\n",
      "other      2680\n",
      "media       162\n",
      "acad         62\n",
      "tourbiz       3\n",
      "gov           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hand.label_simplified\n",
       "other      0.921596\n",
       "media      0.055708\n",
       "acad       0.021320\n",
       "tourbiz    0.001032\n",
       "gov        0.000344\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(spill_labeled_accs.size)\n",
    "\n",
    "print(spill_labeled_accs[\"hand.label_simplified\"].value_counts())\n",
    "\n",
    "spill_labeled_accs[\"hand.label_simplified\"].value_counts(\"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90e98606-aa67-431b-b022-a4de1008c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the rows labeled as other\n",
    "mask = spill_labeled_accs[\"hand.label_simplified\"] == 'other'\n",
    "\n",
    "\n",
    "row_list = []\n",
    "# Check if any of the probabilities (except 'other_prob') are greater than 0.3\n",
    "for index, row in spill_labeled_accs[mask].iterrows():\n",
    "    for col in ['acad_prob', 'gov_prob', 'media_prob', 'other_prob', 'tourbiz_prob']:\n",
    "        if col != 'other_prob' and row[col] > 0.3:\n",
    "            # saving the columns to review\n",
    "            row_list.append(row)\n",
    "            # Update the prediction column to the column name where the probability is higher than 0.3\n",
    "            #spill_labeled_accs.at[index, \"hand.label_simplified\"] = col.replace('_prob', '')\n",
    "rows_for_review = pd.DataFrame(row_list)\n",
    "rows_for_review = rows_for_review.drop_duplicates()\n",
    "#print(rows_for_review)\n",
    "\n",
    "rows_for_review.to_csv(\"Accounts_To_Relabel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e70eb64-18a4-4ac1-9b23-4c02e05c8006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand.label_simplified\n",
      "other      2680\n",
      "media       162\n",
      "acad         62\n",
      "tourbiz       3\n",
      "gov           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hand.label_simplified\n",
       "other      0.921596\n",
       "media      0.055708\n",
       "acad       0.021320\n",
       "tourbiz    0.001032\n",
       "gov        0.000344\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(spill_labeled_accs[\"hand.label_simplified\"].value_counts())\n",
    "\n",
    "spill_labeled_accs[\"hand.label_simplified\"].value_counts(\"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b534871b-8605-4fb8-ba09-4e9c07c4f346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            username                                        description  \\\n",
      "0      ChungSunPark4                                      attempt me!!!   \n",
      "1       LucilaQuanti  Me gusta la gente con sentido del humor, alegr...   \n",
      "2      patdefranchis  I love people with a large dose of humor & a r...   \n",
      "3      saravastiares  Have courage & Be Kind. Where there is kindnes...   \n",
      "4     TheShogunGamer  Video Game Extraordinaire üéÆ Polyamorous ‚ù§ Disa...   \n",
      "...              ...                                                ...   \n",
      "2903       meevans59  Retired Department of Defense civilian employe...   \n",
      "2904          dvdhnz  Techie by trade, recalcitrant by design, socia...   \n",
      "2905      ryantpa813  Eight One Three Sports\\nBolts, Bucs, Rays, Soo...   \n",
      "2906    purpletang99  i tweet my opinions only. yes there are except...   \n",
      "2907      firefly909  Unapologetic bleeding heart liberal. Hate liar...   \n",
      "\n",
      "                                 description_lemmatized hand.label_simplified  \\\n",
      "0                      ['attempt', 'me', '!', '!', '!']                 other   \n",
      "1     ['me', 'gusta', 'la', 'gente', 'con', 'sentido...                 other   \n",
      "2     ['i', 'love', 'people', 'with', 'a', 'large', ...                 other   \n",
      "3     ['have', 'courage', '&', 'be', 'kind', '.', 'w...                 other   \n",
      "4     ['video', 'game', 'extraordinaire', 'üéÆ', 'poly...                 other   \n",
      "...                                                 ...                   ...   \n",
      "2903  ['retired', 'department', 'of', 'defense', 'ci...                 other   \n",
      "2904  ['techie', 'by', 'trade', ',', 'recalcitrant',...                 other   \n",
      "2905  ['eight', 'one', 'three', 'sport', 'bolt', ','...                 other   \n",
      "2906  ['i', 'tweet', 'my', 'opinion', 'only', '.', '...                 other   \n",
      "2907  ['unapologetic', 'bleed', 'heart', 'liberal', ...                 other   \n",
      "\n",
      "      acad_prob  gov_prob  media_prob  other_prob  tourbiz_prob  \n",
      "0      0.000776  0.000603    0.004676    0.993783      0.000162  \n",
      "1      0.009851  0.001305    0.006343    0.981409      0.001092  \n",
      "2      0.003543  0.000746    0.004899    0.990260      0.000552  \n",
      "3      0.003940  0.000537    0.007693    0.985011      0.002819  \n",
      "4      0.000925  0.000598    0.003607    0.994229      0.000641  \n",
      "...         ...       ...         ...         ...           ...  \n",
      "2903   0.001988  0.004162    0.002987    0.990808      0.000055  \n",
      "2904   0.015865  0.002104    0.001636    0.978123      0.002272  \n",
      "2905   0.000745  0.001396    0.033677    0.962982      0.001200  \n",
      "2906   0.003356  0.000360    0.076140    0.919635      0.000509  \n",
      "2907   0.000927  0.000073    0.000698    0.998056      0.000247  \n",
      "\n",
      "[2908 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(spill_labeled_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65319d29-2b4b-4cf7-a9ac-941aa25480d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 9)\n",
      "             username                                        description  \\\n",
      "0             004nino  Retrait√©.√âgalit√©,fraternit√©,justice,libert√©,na...   \n",
      "1              00a03d  Mom of one, grandma of two, sister of six, aun...   \n",
      "2     05adamlover0129  LOVE Adam Lambert for life!!! Also love Miami ...   \n",
      "3     0Plongstocking2  Not a traitor. Traveler. Liker of food. Orchid...   \n",
      "4             0Thessa  üíö... sch√∂nheit\\nist die natur! die kunst ist u...   \n",
      "...               ...                                                ...   \n",
      "3493   zoeycarmicheal  The Univ. of Alabama Alumni. Former Gymnast an...   \n",
      "3494           zpleat  Research at Media Matters for America. All twe...   \n",
      "3495         zshahan3  Human (maybe), writer + chief editor + CEO @Cl...   \n",
      "3496          zul1732  You can't see people for what they are when yo...   \n",
      "3497        zyiteblog  E-Scootersworld is global Power transport reta...   \n",
      "\n",
      "                                 description_lemmatized hand.label_simplified  \\\n",
      "0     ['retrait√©.√©galit√©', ',', 'fraternit√©', ',', '...                 other   \n",
      "1     ['mom', 'of', 'one', ',', 'grandma', 'of', 'tw...                 other   \n",
      "2     ['love', 'adam', 'lambert', 'for', 'life', '!'...                 other   \n",
      "3     ['not', 'a', 'traitor', '.', 'traveler', '.', ...                 other   \n",
      "4     ['üíö', '...', 'sch√∂nheit', 'ist', 'die', 'natur...                 other   \n",
      "...                                                 ...                   ...   \n",
      "3493  ['the', 'univ', '.', 'of', 'alabama', 'alumnus...                 other   \n",
      "3494  ['research', 'at', 'media', 'matter', 'for', '...                 other   \n",
      "3495  ['human', '(', 'maybe', ')', ',', 'writer', '+...                 media   \n",
      "3496  ['you', 'ca', \"n't\", 'see', 'people', 'for', '...                 other   \n",
      "3497  ['e-scootersworld', 'be', 'global', 'power', '...                 other   \n",
      "\n",
      "      acad_prob  gov_prob  media_prob  other_prob  tourbiz_prob  \n",
      "0      0.017303  0.002636    0.010321    0.969045      0.000695  \n",
      "1      0.008145  0.002770    0.011733    0.977149      0.000203  \n",
      "2      0.005680  0.000770    0.202065    0.788418      0.003066  \n",
      "3      0.006012  0.005455    0.001879    0.980456      0.006198  \n",
      "4      0.014347  0.017324    0.018455    0.948339      0.001535  \n",
      "...         ...       ...         ...         ...           ...  \n",
      "3493   0.003370  0.003790    0.041372    0.948383      0.003084  \n",
      "3494   0.031496  0.002862    0.050988    0.914259      0.000394  \n",
      "3495   0.004032  0.000303    0.693154    0.302204      0.000308  \n",
      "3496   0.005312  0.000945    0.001609    0.986842      0.005293  \n",
      "3497   0.005406  0.005807    0.019533    0.938352      0.030902  \n",
      "\n",
      "[3498 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "spill_accs_merged = pd.merge(spill_labeled_accs, empty_rows, how=\"outer\")\n",
    "\n",
    "print(spill_accs_merged.shape)\n",
    "print(spill_accs_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c61f255-89d1-455c-b08b-cf584df4fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              username                                        description  \\\n",
      "0                  CNN  It‚Äôs our job to #GoThere & tell the most diffi...   \n",
      "1               NatGeo  Taking our understanding and awareness of the ...   \n",
      "2              FoxNews  Follow America's #1 cable news network, delive...   \n",
      "3       washingtonpost                         Democracy Dies in Darkness   \n",
      "4                  ABC  The only official ABC News Twitter account. Do...   \n",
      "...                ...                                                ...   \n",
      "29128  EvergreenZephyr  Wichita, Kansas, United (sic) States. Parody a...   \n",
      "29129         johntfox  Madeleine & Marin's Dad | Gin Enthusiast | Twe...   \n",
      "29130         SeGreene  Cranky former nurse and current plant patholog...   \n",
      "29131      CherylLasse  Passionate about the environment, science and ...   \n",
      "29132          jen_pic  üö´socialism. Pay your debts, ALL OF THEM! Nothi...   \n",
      "\n",
      "       Label Label.Type  \n",
      "0      media       Hand  \n",
      "1      media       Hand  \n",
      "2      media       Hand  \n",
      "3      media       Hand  \n",
      "4      media       Hand  \n",
      "...      ...        ...  \n",
      "29128  other    Predict  \n",
      "29129  other    Predict  \n",
      "29130  other    Predict  \n",
      "29131  other    Predict  \n",
      "29132  other    Predict  \n",
      "\n",
      "[29133 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# acccounts labeled during Red-Tide research\n",
    "prev_accs = pd.read_csv(\"Final_Account_Labels_for_Dashboard.csv\")\n",
    "print(prev_accs)\n",
    "accounts_merged = pd.concat([spill_accs_merged, prev_accs], ignore_index=True)\n",
    "\n",
    "accounts_merged.to_csv(\"ALL_Labeled_Accounts_Spill&RedTide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "28303242-c700-4917-b0b4-4f62a86581cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand.label_simplified\n",
      "other    261\n",
      "media     31\n",
      "acad      19\n",
      "Name: count, dtype: int64\n",
      "hand.label_simplified\n",
      "other    0.839228\n",
      "media    0.099678\n",
      "acad     0.061093\n",
      "Name: proportion, dtype: float64\n",
      "hand.label_simplified\n",
      "other      215\n",
      "media        9\n",
      "acad         4\n",
      "tourbiz      1\n",
      "gov          1\n",
      "Name: count, dtype: int64\n",
      "hand.label_simplified\n",
      "other      0.934783\n",
      "media      0.039130\n",
      "acad       0.017391\n",
      "tourbiz    0.004348\n",
      "gov        0.004348\n",
      "Name: proportion, dtype: float64\n",
      "hand.label_simplified\n",
      "other      2232\n",
      "media       127\n",
      "acad         39\n",
      "tourbiz       2\n",
      "gov           1\n",
      "Name: count, dtype: int64\n",
      "hand.label_simplified\n",
      "other      0.929613\n",
      "media      0.052895\n",
      "acad       0.016243\n",
      "tourbiz    0.000833\n",
      "gov        0.000416\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "oil = pd.read_csv(\"../spill_data/All_OilSpill.csv\")\n",
    "sewage = pd.read_csv(\"../spill_data/All_SewageSpill.csv\")\n",
    "industrial = pd.read_csv(\"../spill_data/All_IndustrialSpill.csv\")\n",
    "\n",
    "oil_accs = accounts_merged[accounts_merged[\"username\"].isin(oil[\"username\"])]\n",
    "print(oil_accs[\"hand.label_simplified\"].value_counts())\n",
    "print(oil_accs[\"hand.label_simplified\"].value_counts(\"row\"))\n",
    "\n",
    "sewage_accs = accounts_merged[accounts_merged[\"username\"].isin(sewage[\"username\"])]\n",
    "print(sewage_accs[\"hand.label_simplified\"].value_counts())\n",
    "print(sewage_accs[\"hand.label_simplified\"].value_counts(\"row\"))\n",
    "\n",
    "industrial_accs = accounts_merged[accounts_merged[\"username\"].isin(industrial[\"username\"])]\n",
    "print(industrial_accs[\"hand.label_simplified\"].value_counts())\n",
    "print(industrial_accs[\"hand.label_simplified\"].value_counts(\"row\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949f866-2efb-4a67-a2c8-e4c4df85e92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e37f6f24e9a9f73ff6720cc463cd31ad7ef16f22c85d3da331e44c0f6e80d360"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
